{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "diagnostic-merchandise",
   "metadata": {},
   "source": [
    "**Author:** Elias Rafael Ruiz-Morales\n",
    "\n",
    "**Institution:** Wellcome Sanger institute\n",
    "\n",
    "**July, 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-fundamental",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-sherman",
   "metadata": {},
   "source": [
    "## Code to load the data and detect doublets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-pressure",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: If you miss a compact list, please try `print_header`!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "anndata     0.7.5\n",
      "scanpy      1.7.1\n",
      "sinfo       0.3.1\n",
      "-----\n",
      "PIL                 8.1.2\n",
      "anndata             0.7.5\n",
      "anyio               NA\n",
      "attr                20.3.0\n",
      "babel               2.9.0\n",
      "backcall            0.2.0\n",
      "brotli              NA\n",
      "cairo               1.20.0\n",
      "certifi             2020.12.05\n",
      "cffi                1.14.5\n",
      "chardet             4.0.0\n",
      "cloudpickle         1.6.0\n",
      "colorama            0.4.4\n",
      "cycler              0.10.0\n",
      "cython_runtime      NA\n",
      "cytoolz             0.11.0\n",
      "dask                2021.03.1\n",
      "dateutil            2.8.1\n",
      "decorator           4.4.2\n",
      "fsspec              0.8.7\n",
      "get_version         2.1\n",
      "google              NA\n",
      "h5py                3.1.0\n",
      "idna                2.10\n",
      "igraph              0.8.3\n",
      "ipykernel           5.5.0\n",
      "ipython_genutils    0.2.0\n",
      "jedi                0.18.0\n",
      "jinja2              2.11.3\n",
      "joblib              1.0.1\n",
      "json5               NA\n",
      "jsonschema          3.2.0\n",
      "jupyter_server      1.4.1\n",
      "jupyterlab_server   2.3.0\n",
      "kiwisolver          1.3.1\n",
      "legacy_api_wrap     0.0.0\n",
      "leidenalg           0.8.3\n",
      "llvmlite            0.34.0\n",
      "louvain             0.7.0\n",
      "markupsafe          1.1.1\n",
      "matplotlib          3.3.4\n",
      "mpl_toolkits        NA\n",
      "natsort             7.1.1\n",
      "nbclassic           NA\n",
      "nbformat            5.1.2\n",
      "numba               0.51.2\n",
      "numexpr             2.7.3\n",
      "numpy               1.20.1\n",
      "packaging           20.9\n",
      "pandas              1.2.3\n",
      "parso               0.8.1\n",
      "pexpect             4.8.0\n",
      "pickleshare         0.7.5\n",
      "pkg_resources       NA\n",
      "prometheus_client   NA\n",
      "prompt_toolkit      3.0.16\n",
      "psutil              5.8.0\n",
      "ptyprocess          0.7.0\n",
      "pvectorc            NA\n",
      "pyarrow             0.16.0\n",
      "pygments            2.8.0\n",
      "pyparsing           2.4.7\n",
      "pyrsistent          NA\n",
      "pytoml              NA\n",
      "pytz                2021.1\n",
      "requests            2.25.1\n",
      "ruamel              NA\n",
      "scanpy              1.7.1\n",
      "scipy               1.6.1\n",
      "scrublet            NA\n",
      "send2trash          NA\n",
      "setuptools_scm      NA\n",
      "sinfo               0.3.1\n",
      "six                 1.15.0\n",
      "sklearn             0.24.1\n",
      "sniffio             1.2.0\n",
      "socks               1.7.1\n",
      "sphinxcontrib       NA\n",
      "storemagic          NA\n",
      "tables              3.6.1\n",
      "tblib               1.7.0\n",
      "texttable           1.6.3\n",
      "tlz                 0.11.0\n",
      "toolz               0.11.1\n",
      "tornado             6.1\n",
      "traitlets           5.0.5\n",
      "typing_extensions   NA\n",
      "urllib3             1.26.3\n",
      "wcwidth             0.2.5\n",
      "yaml                5.3.1\n",
      "zmq                 22.0.3\n",
      "-----\n",
      "IPython             7.21.0\n",
      "jupyter_client      6.1.11\n",
      "jupyter_core        4.7.1\n",
      "jupyterlab          3.0.9\n",
      "notebook            6.2.0\n",
      "-----\n",
      "Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]\n",
      "Linux-4.15.0-213-generic-x86_64-with-glibc2.10\n",
      "26 logical CPU cores, x86_64\n",
      "-----\n",
      "Session information updated at 2023-11-27 12:55\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/opt/conda/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scrublet as scr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "def MovePlots(plotpattern, subplotdir):\n",
    "    os.system('mkdir -p '+str(sc.settings.figdir)+'/'+subplotdir)\n",
    "    os.system('mv '+str(sc.settings.figdir)+'/*'+plotpattern+'** '+str(sc.settings.figdir)+'/'+subplotdir)\n",
    "\n",
    "\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.figdir = '../results/images/preprocessing/'\n",
    "sc.logging.print_versions()\n",
    "sc.settings.set_figure_params(dpi=80)  # low dpi (dots per inch) yields small inline figures\n",
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executive-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benjamini-Hochberg and Bonferroni FDR helper functions.\n",
    "\n",
    "def bh(pvalues):\n",
    "    \"\"\"\n",
    "    Computes the Benjamini-Hochberg FDR correction.\n",
    "    \n",
    "    Input:\n",
    "        * pvals - vector of p-values to correct\n",
    "    \"\"\"\n",
    "    pvalues = np.array(pvalues)\n",
    "    n = int(pvalues.shape[0])\n",
    "    new_pvalues = np.empty(n)\n",
    "    values = [ (pvalue, i) for i, pvalue in enumerate(pvalues) ]\n",
    "    values.sort()\n",
    "    values.reverse()\n",
    "    new_values = []\n",
    "    for i, vals in enumerate(values):\n",
    "        rank = n - i\n",
    "        pvalue, index = vals\n",
    "        new_values.append((n/rank) * pvalue)\n",
    "    for i in range(0, int(n)-1):\n",
    "        if new_values[i] < new_values[i+1]:\n",
    "            new_values[i+1] = new_values[i]\n",
    "    for i, vals in enumerate(values):\n",
    "        pvalue, index = vals\n",
    "        new_pvalues[index] = new_values[i]\n",
    "    return new_pvalues\n",
    "\n",
    "\n",
    "def bonf(pvalues):\n",
    "    \"\"\"\n",
    "    Computes the Bonferroni FDR correction.\n",
    "    \n",
    "    Input:\n",
    "        * pvals - vector of p-values to correct\n",
    "    \"\"\"\n",
    "    new_pvalues = np.array(pvalues) * len(pvalues)\n",
    "    new_pvalues[new_pvalues>1] = 1\n",
    "    return new_pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-child",
   "metadata": {},
   "source": [
    "## Scrumblet\n",
    "\n",
    "(Courtesy of K Polansky)\n",
    "\n",
    "Two-step doublet score processing, mirroring the approach from Popescu et al. https://www.nature.com/articles/s41586-019-1652-y which was closely based on Pijuan-Sala et al. https://www.nature.com/articles/s41586-019-0933-9\n",
    "\n",
    "The first step starts with some sort of doublet score, e.g. Scrublet, and ends up with a per-cell p-value (with significant values marking doublets). For each sample individually:\n",
    "\n",
    " - run Scrublet to obtain each cell's score\n",
    "- overcluster the manifold - run a basic Scanpy pipeline up to clustering, then additionally cluster each cluster separately\n",
    "- compute per-cluster Scrublet scores as the median of the observed values, and use those going forward\n",
    "- identify p-values:\n",
    "  - compute normal distribution parameters: centered at the median of the scores, with a MAD-derived standard deviation\n",
    "  - the score distribution is zero-truncated, so as per the paper I only use above-median values to compute the MAD\n",
    "  - K deviates from the paper a bit, at least the exact wording captured within it, and multiply the MAD by 1.4826 to obtain a literature-derived normal distribution standard deviation estimate\n",
    "  - FDR-correct the p-values via Benjamini-Hochberg\n",
    "- write out all this doublet info into CSVs for later use\n",
    "\n",
    "NOTE: The second step is performed later, in a multi-sample space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lyric-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def runScrublet(samples, data_dir):\n",
    "\n",
    "    for sample in reversed(list(samples)):\n",
    "        print(sample)\n",
    "        #import data\n",
    "        adata_sample = sc.read_10x_mtx(data_dir+sample+'/output/GeneFull/filtered/',var_names='gene_symbols',cache=True) #reading the data\n",
    "        #adata_sample = sc.read_10x_mtx(data_dir+sample+'/soupX_filt/')\n",
    "        #for un-souped data:: adata_sample = sc.read_10x_h5(data_dir+sample+'/filtered_feature_bc_matrix.h5')\n",
    "        adata_sample.var_names_make_unique()\n",
    "        #rename cells to SAMPLE_BARCODE\n",
    "        adata_sample.obs_names = [sample+'_'+i for i in adata_sample.obs_names]\n",
    "        #do some early filtering to retain meaningful cells for doublet inspection\n",
    "        sc.pp.filter_cells(adata_sample, min_genes=200)\n",
    "        sc.pp.filter_genes(adata_sample, min_cells=3)\n",
    "\n",
    "        #convert to lower to be species agnostic: human mito start with MT-, mouse with mt-\n",
    "        mito_genes = [name for name in adata_sample.var_names if name.lower().startswith('mt-')]\n",
    "        # for each cell compute fraction of counts in mito genes vs. all genes\n",
    "        # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)\n",
    "        #adata_sample.obs['percent_mito'] = np.sum(\n",
    "        #    adata_sample[:, mito_genes].X, axis=1).A1 / np.sum(adata_sample.X, axis=1).A1\n",
    "        #adata_sample = adata_sample[adata_sample.obs['percent_mito'] < 0.2, :]\n",
    "\n",
    "        #set up and run Scrublet, seeding for replicability\n",
    "        np.random.seed(0)\n",
    "        scrub = scr.Scrublet(adata_sample.X)\n",
    "        doublet_scores, predicted_doublets = scrub.scrub_doublets(verbose=False)\n",
    "        adata_sample.obs['scrublet_score'] = doublet_scores\n",
    "\n",
    "        #overcluster prep. run turbo basic scanpy pipeline\n",
    "        sc.pp.normalize_per_cell(adata_sample, counts_per_cell_after=1e4)\n",
    "        sc.pp.log1p(adata_sample)\n",
    "        sc.pp.highly_variable_genes(adata_sample, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "        adata_sample = adata_sample[:, adata_sample.var['highly_variable']]\n",
    "        sc.pp.scale(adata_sample, max_value=10)\n",
    "        sc.tl.pca(adata_sample, svd_solver='arpack')\n",
    "        sc.pp.neighbors(adata_sample)\n",
    "        #overclustering proper - do basic clustering first, then cluster each cluster\n",
    "        sc.tl.leiden(adata_sample)\n",
    "        adata_sample.obs['leiden'] = [str(i) for i in adata_sample.obs['leiden']]\n",
    "        for clus in np.unique(adata_sample.obs['leiden']):\n",
    "            adata_sub = adata_sample[adata_sample.obs['leiden']==clus].copy()\n",
    "            sc.tl.leiden(adata_sub)\n",
    "            adata_sub.obs['leiden'] = [clus+','+i for i in adata_sub.obs['leiden']]\n",
    "            adata_sample.obs.loc[adata_sub.obs_names,'leiden'] = adata_sub.obs['leiden']\n",
    "\n",
    "        #compute the cluster scores - the median of Scrublet scores per overclustered cluster\n",
    "        for clus in np.unique(adata_sample.obs['leiden']):\n",
    "            adata_sample.obs.loc[adata_sample.obs['leiden']==clus, 'scrublet_cluster_score'] = \\\n",
    "                np.median(adata_sample.obs.loc[adata_sample.obs['leiden']==clus, 'scrublet_score'])\n",
    "        #now compute doublet p-values. figure out the median and mad (from above-median values) for the distribution\n",
    "        med = np.median(adata_sample.obs['scrublet_cluster_score'])\n",
    "        mask = adata_sample.obs['scrublet_cluster_score']>med\n",
    "        mad = np.median(adata_sample.obs['scrublet_cluster_score'][mask]-med)\n",
    "        #let's do a one-sided test. the Bertie write-up does not address this but it makes sense\n",
    "        zscores = (adata_sample.obs['scrublet_cluster_score'].values - med) / (1.4826 * mad)\n",
    "        adata_sample.obs['zscore'] = zscores\n",
    "        pvals = 1-scipy.stats.norm.cdf(zscores)\n",
    "        adata_sample.obs['bh_pval'] = bh(pvals)\n",
    "        adata_sample.obs['bonf_pval'] = bonf(pvals)\n",
    "\n",
    "        #create results data frame for single sample and copy stuff over from the adata object\n",
    "        scrublet_sample = pd.DataFrame(0, index=adata_sample.obs_names, columns=scorenames)\n",
    "        for score in scorenames:\n",
    "            scrublet_sample[score] = adata_sample.obs[score]\n",
    "\n",
    "        #write out complete sample scores\n",
    "        scrublet_sample.to_csv(outputDir+sample+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-climb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "right-blanket",
   "metadata": {},
   "source": [
    "### Reading Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "copyrighted-defense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples Lm:  4\n",
      "Number of samples Pf:  4\n",
      "Number of samples Tg:  4\n"
     ]
    }
   ],
   "source": [
    "#Listeria infected metadata\n",
    "metaLm = pd.read_csv('../data/Listeria/meta_exp_infection_Lm_scell.csv',index_col=0)\n",
    "metaLm['donor'] = metaLm['donor'].astype('str')\n",
    "print('Number of samples Lm: ', metaLm.index.size)\n",
    "\n",
    "#Plasmodium infected metadata\n",
    "metaPf = pd.read_csv('../data/Malaria/meta_exp_infection_2d9_scell.csv',index_col=0)\n",
    "metaPf['donor'] = metaPf['donor'].astype('str')\n",
    "print('Number of samples Pf: ', metaPf.index.size)\n",
    "\n",
    "#Toxoplasma infected metadata\n",
    "metaTg = pd.read_csv('../data/Toxoplasma/meta_exp_infection_Tg_scell.csv',index_col=0)\n",
    "metaTg['donor'] = metaTg['donor'].astype('str')\n",
    "print('Number of samples Tg: ', metaTg.index.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intimate-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>donor</th>\n",
       "      <th>hpi</th>\n",
       "      <th>infection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pla_HDBR13007976</th>\n",
       "      <td>UI_48h</td>\n",
       "      <td>Hrv171_Hrv172</td>\n",
       "      <td>48h</td>\n",
       "      <td>UI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pla_HDBR13007977</th>\n",
       "      <td>Tg_48h</td>\n",
       "      <td>Hrv171_Hrv172</td>\n",
       "      <td>48h</td>\n",
       "      <td>Tg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pla_HDBR13798225</th>\n",
       "      <td>UI_48h</td>\n",
       "      <td>Hrv241_Hrv242</td>\n",
       "      <td>48h</td>\n",
       "      <td>UI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pla_HDBR13798226</th>\n",
       "      <td>Tg_48h</td>\n",
       "      <td>Hrv241_Hrv242</td>\n",
       "      <td>48h</td>\n",
       "      <td>Tg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stage          donor  hpi infection\n",
       "sample                                                \n",
       "Pla_HDBR13007976  UI_48h  Hrv171_Hrv172  48h        UI\n",
       "Pla_HDBR13007977  Tg_48h  Hrv171_Hrv172  48h        Tg\n",
       "Pla_HDBR13798225  UI_48h  Hrv241_Hrv242  48h        UI\n",
       "Pla_HDBR13798226  Tg_48h  Hrv241_Hrv242  48h        Tg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaTg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-employee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "awful-encyclopedia",
   "metadata": {},
   "source": [
    "## Reading and saving the files as .h5 for the pipeline\n",
    "Please remember that STARsolo v2.7.9a returns the file genes.tsv.gz, however scanpy now only reads the file features.tsv.gz.\n",
    "Just change the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painted-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there's loads of clustering going on, so set verbosity low unless you enjoy walls of text\n",
    "sc.settings.verbosity = 0  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "\n",
    "scorenames = ['scrublet_score','scrublet_cluster_score','zscore','bh_pval','bonf_pval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-alpha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "precious-hamburg",
   "metadata": {},
   "source": [
    "#### Listeria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instrumental-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#output directory\n",
    "out_dir = '/lustre/scratch126/cellgen/team292/er13/PlacInfection_revision/scRNAseq/data_integration/48h/data/Listeria/'\n",
    "\n",
    "\n",
    "if not os.path.exists(out_dir+'scrublet-scores'):\n",
    "    os.makedirs(out_dir+'scrublet-scores')\n",
    "    #loop over the subfolders of the rawdata folder\n",
    "\n",
    "outputDir=out_dir+'scrublet-scores/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-delight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13661576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13661575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR12330715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR12330714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "runScrublet(metaLm.index.to_list(), data_dir='/lustre/scratch126/cellgen/team292/er13/PlacInfection_revision/scRNAseq/data_integration/24h/data/Listeria/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-darwin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "central-freeze",
   "metadata": {},
   "source": [
    "#### Malaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "received-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#output directory\n",
    "out_dir = '/lustre/scratch126/cellgen/team292/er13/PlacInfection_revision/scRNAseq/data_integration/48h/data/Malaria/'\n",
    "\n",
    "\n",
    "if not os.path.exists(out_dir+'scrublet-scores'):\n",
    "    os.makedirs(out_dir+'scrublet-scores')\n",
    "    #loop over the subfolders of the rawdata folder\n",
    "\n",
    "outputDir=out_dir+'scrublet-scores/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "innovative-yeast",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13661574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13661573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13661568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13661567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "runScrublet(metaPf.index.to_list(), data_dir='/lustre/scratch126/cellgen/team292/er13/PlacInfection_revision/scRNAseq/data_integration/24h/data/Malaria/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-bookmark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-budapest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-concept",
   "metadata": {},
   "source": [
    "#### Toxoplasma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "divine-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output directory\n",
    "out_dir = '/lustre/scratch126/cellgen/team292/er13/PlacInfection_revision/scRNAseq/data_integration/48h/data/Toxoplasma/'\n",
    "\n",
    "\n",
    "if not os.path.exists(out_dir+'scrublet-scores'):\n",
    "    os.makedirs(out_dir+'scrublet-scores')\n",
    "    #loop over the subfolders of the rawdata folder\n",
    "\n",
    "outputDir=out_dir+'scrublet-scores/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-cleveland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13798226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pla_HDBR13798225\n"
     ]
    }
   ],
   "source": [
    "runScrublet(metaTg.index.to_list(), data_dir='/lustre/scratch126/cellgen/team292/er13/PlacInfection_revision/scRNAseq/data_integration/24h/data/Toxoplasma/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-belly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-thirty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
